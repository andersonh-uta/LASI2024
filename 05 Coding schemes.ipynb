{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "T5IdUxmU8lxm",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ac6923ef-3302-4058-8ecf-07c42fc1957c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Installing collected packages: h11, httpcore, httpx, openai\n",
      "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0\n",
      "Collecting docx\n",
      "  Downloading docx-0.2.4.tar.gz (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docx) (4.9.4)\n",
      "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.10/dist-packages (from docx) (9.4.0)\n",
      "Building wheels for collected packages: docx\n",
      "  Building wheel for docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docx: filename=docx-0.2.4-py3-none-any.whl size=53895 sha256=a4e810a10061d5ecf190b06f79c4a21698a7d69197d7b60397e9ffe0df16bd5b\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/f5/1d/e09ba2c1907a43a4146d1189ae4733ca1a3bfe27ee39507767\n",
      "Successfully built docx\n",
      "Installing collected packages: docx\n",
      "Successfully installed docx-0.2.4\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install docx\n",
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FDbP9Rv8kH_"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "import time\n",
    "import openpyxl\n",
    "import requests as req\n",
    "import os\n",
    "import time\n",
    "from types import NoneType\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKL5EYHP5-Ew"
   },
   "outputs": [],
   "source": [
    "strategies_list = [\n",
    "    \"organizing and transforming\", \"goal setting and planning\", \"seeking information\",\n",
    "    \"keeping records and monitoring\", \"environmental structuring\", \"self-consequences\", \"rehearsing and memorizing\",\n",
    "    \"seeking social assistance\", \"reviewing records\", \"other\"\n",
    "]\n",
    "\n",
    "strategies_list = list(map(lambda x: x.lower(), strategies_list))\n",
    "\n",
    "strategies_abbr = [\n",
    "    \"org.\", \"planning\", \"seek.info\",\n",
    "    \"keep.rec.\", \"env.\", \"self.cons.\", \"reaherse.\",\n",
    "    \"seek.social\", \"review.rec.\", \"others\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1bSAB8E6in7"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "I would like to invite you to participate as a linguistic researcher in my research project. The objective of this project is to analyse written reflections from students concerning their self-regulated learning (SRL) strategies. I have asked the students to reflect on the learning strategies they employed in their previous work. My main goal is to determine whether students mention self-regulated learning strategies in their assessments and, if they do, what specific SRL strategies they mention. It's important to note that a single sentence in a student's reflection may reflect multiple SRL strategies, indicating the complexity and interconnectedness of self-regulated learning processes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTCBBUKdU8ig"
   },
   "outputs": [],
   "source": [
    "def docx_to_string(file_path):\n",
    "    # Open the .docx file\n",
    "    doc = Document(file_path)\n",
    "    # Read and concatenate all the text from the document\n",
    "    full_text = [paragraph.text for paragraph in doc.paragraphs]\n",
    "    return '\\n'.join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "mG4ftTMykJ40",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "user_prompt = docx_to_string('/content/sourcedata/prompt-1-shot.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VFVzSiBlw7q"
   },
   "outputs": [],
   "source": [
    "def is_numeric(val):\n",
    "    \"\"\"Check if the value is numeric.\"\"\"\n",
    "    try:\n",
    "        int(val)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbUWg3N28unP"
   },
   "outputs": [],
   "source": [
    "def getOpenAIResp(sys, user, modelid):\n",
    "\n",
    "  resp = client.chat.completions.create(\n",
    "    model = modelid,\n",
    "    messages=[\n",
    "       {\"role\": \"system\", \"content\": sys},\n",
    "       {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    "  )\n",
    "  return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80EF3aggl0IW"
   },
   "outputs": [],
   "source": [
    "def call_openai_api(system_prompt, user_prompt, model):\n",
    "    c3l_openai_key = 'PASTE YOUR OPENAI API KEY HERE'\n",
    "    client = OpenAI(api_key=c3l_openai_key)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "      model=model,\n",
    "      temperature = 0,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    result = completion.choices[0].message.content\n",
    "    time.sleep(1)  # Simulate network delay\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7Xp3e8Npb99"
   },
   "outputs": [],
   "source": [
    "def get_strategies(api_responses):\n",
    "\n",
    "  # Escape special characters in strategy names and create a regex pattern\n",
    "  escaped_strategies = [re.escape(strategy) for strategy in strategies_list]\n",
    "  pattern = r'\\b(' + '|'.join(escaped_strategies) + r')\\b'\n",
    "\n",
    "  # Find all matches in the text\n",
    "  found_strategies = re.findall(pattern, api_responses, re.IGNORECASE)\n",
    "\n",
    "  return found_strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMNh3zy9bA_S"
   },
   "outputs": [],
   "source": [
    "def print_reasoning_excel(rdict):\n",
    "  # Convert the dictionary to a pandas DataFrame\n",
    "  df = pd.DataFrame.from_dict(rdict, orient='index')\n",
    "\n",
    "  # Export the DataFrame to an Excel file\n",
    "  df.to_excel('reasoning.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ho0c56vi0VXE"
   },
   "outputs": [],
   "source": [
    "def print_reflection_coding_excel(rdict, num_runs):\n",
    "    \"\"\"\n",
    "    Generates detailed and summary Excel files from reflection coding data.\n",
    "\n",
    "    Args:\n",
    "        reflection_dict (dict): Dictionary containing reflection coding data.\n",
    "        num_runs (int): Number of runs to consider for calculating majority votes.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Lists to hold row data for detailed and summary DataFrames\n",
    "    details_rows = []\n",
    "    summary_rows = []\n",
    "\n",
    "    # Iterate over the reflection coding data\n",
    "    for row_number, strategies in rdict.items():\n",
    "        row_data = {} # Dictionary to hold detailed row data\n",
    "        summary_data = {} # Dictionary to hold summary row data\n",
    "\n",
    "        # Iterate over each strategy in the row\n",
    "        for strategy, runs in strategies.items():\n",
    "            votes = [] # List to keep track of votes for the strategy\n",
    "\n",
    "            # Iterate over each run for the current strategy\n",
    "            for run_number, value in runs.items():\n",
    "                # Generate a column name for the strategy and run\n",
    "                column_name = f\"{strategy}_run{run_number}\"\n",
    "                row_data[column_name] = value  # Assign the value (0 or 1)\n",
    "                votes.append(value)\n",
    "\n",
    "            # Calculate majority vote for the strategy\n",
    "            if votes.count(1) > num_runs / 2:\n",
    "                summary_data[strategy] = 1\n",
    "            else:\n",
    "                summary_data[strategy] = 0\n",
    "\n",
    "        # Add the detailed and summary row data to their respective lists\n",
    "        details_rows.append(row_data)\n",
    "        summary_rows.append(summary_data)\n",
    "\n",
    "    # Create DataFrame for detailed data and save to Excel\n",
    "    df = pd.DataFrame(details_rows)\n",
    "    df.index += 1\n",
    "    df.to_excel('strategies_detailed.xlsx', engine='openpyxl')\n",
    "\n",
    "    # Convert the summary data into another DataFrame\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_df.index += 1\n",
    "    summary_df.to_excel('strategies_summary.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeVEpX2CMkKG"
   },
   "outputs": [],
   "source": [
    "def print_coding(rdict, num_rows, num_iter):\n",
    "  \"\"\"\n",
    "  Processes reflection data and prints a coding dictionary for analysis.\n",
    "\n",
    "  Args:\n",
    "      reflection_dict (dict): Dictionary containing reflection data.\n",
    "      num_rows (int): Number of rows to consider for processing.\n",
    "      num_iter (int): Number of iterations for coding.\n",
    "\n",
    "  Returns:\n",
    "      None\n",
    "  \"\"\"\n",
    "\n",
    "  # Dictionary to store the final coded reflections\n",
    "  reflection_coding_dict = {}\n",
    "\n",
    "  # Iterate over the reflection dictionary\n",
    "  for k, v in rdict.items():\n",
    "\n",
    "    # Initialize a temporary coding dictionary for the current row\n",
    "    temp_coding_dict = {\n",
    "      row: {\n",
    "          s: {i: 0 for i in range(1, num_iter + 1)}\n",
    "          for s in strategies_abbr\n",
    "      } for row in range(k, num_rows + k)\n",
    "    }\n",
    "\n",
    "    # Iterate over each API call response\n",
    "    for run, codes_text in v.items():\n",
    "      # Extract strategies from the response text\n",
    "      for strat in get_strategies(codes_text):\n",
    "        # Find the corresponding strategy ID\n",
    "        strategy_id = strategies_list.index(strat.lower())\n",
    "\n",
    "        # Set the coding value to 1 for the identified strategy\n",
    "        temp_coding_dict[k][strategies_abbr[strategy_id]][run] = 1\n",
    "\n",
    "    # Store the coded data for the current row\n",
    "    reflection_coding_dict[k] = temp_coding_dict[k]\n",
    "\n",
    "  # Generate an Excel file with the coded reflection data\n",
    "  print_reflection_coding_excel(reflection_coding_dict, num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEnjC56mlrWF",
    "outputId": "ff371f64-5d56-43c3-d494-6c4db7931400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ID: 11 | Text: Changed up a few things but mainly stuck with the plan, didn't end up with enough time due to other circumstances. \n",
      "Processing ID: 14 | Text: To compare the two articles, I first critically read and analysed each of them. Upon comprehension, it became evident that the article I chose myself was denser in academic content in contrast to the casually written recount in the Geist & Jung (2022) article. This became my focus regarding comparison of the two articles. I used the method of Boolean operators in order to locate a related article on the UniSA library data base. I searched the term ‘early childhood education AND garden-based learning’, which led me to finding the Murakami, Russell & Manfra (2018) article. This article complemented the Geist & Jung article in that it was based on the concept of garden-based learning in early childhood education, but also contained a case study analysis.\n",
      "Processing ID: 15 | Text: My initial strategy was to locate a recent article that linked with the idea of discussed online learning during the pandemic. Quickly I discovered searching within recent times with limited key words was presenting the same articles time and time again. After expanding my search to the last 10 years, playing with key words, downloading many other articles, I found the article for me. It was interesting to me and supported my ideas from article 1. From this point, I read both articles several times, highlighted key ideas plus highlighted two areas to link both articles together. I then felt a sense of accomplishment and transitioning my thoughts to my review came together.\n",
      "Processing ID: 16 | Text: The two main pieces of feedback I received on my first assignment was to try and increase my academic writing for example in the first assignment I used the work kids instead of children. To avoid this mistake again in assignment 2 I read through the assignment a few more times then usual and tried and correct any of these mistakes. \n",
      "The second piece of feedback I received was to work on my referencing. Referencing is something I struggle with and find difficult. I tried to write my references as soon as I found them to avoid stressing and incorrectly writing them.\n",
      "Processing ID: 18 | Text: In terms of academic skills used in Assignment 1 compared to assignment 2 are the same strategies used in terms of reviewing all of the necessary information multiple time to make sure I had what was needed, also rewatching lectures, re reading, readings and additional notes about the course work. THe re watch, re reading and additional noting helped me in finding detailed information for the focus area and connections area sections of my assignment and giving myself an informative insight into what would make me a better teacher for the future. \n",
      "Processing ID: 19 | Text: When choosing an article to compare to ‘Including Videos in Early Childhood Lessons’ I searched for key words and themes including ‘videos’, ‘technology’ ‘early childhood’ and ‘education.’ I sourced my article using the UniSA library search tool and filtering my search to peer-reviewed articles published within the last ten years, along with these key words. I read, highlighted and annotated three relevant journal articles before finally selecting one. I chose the article, ‘Early Childhood Learning Videos on YouTube: A Thematic Analysis of Viewer’s Perceptions’ as it presents many valuable similarities to the first article, including an analysis of the impact of videos as a learning tool in early childhood education, a discussion of educator’s perceptions regarding educational children’s videos and a reflection on the normalisation of technology in young children’s lives. However, the articles also present differences regarding the aim, research method and data type used for studies, therefore generating slightly different observations. Advantageously, this facilitated a deeper comparison between the articles by prompting me to question how the respective findings in both articles may support each other.\n",
      "Processing ID: 20 | Text: One of the main strategies I used in Assignment 2 which I used in Assignment 1 was finding all the sources and readings before I started writing the assignment. By doing this I was able to write my refrence list at the start and then not have to worry about it at the end. Also, after I wrote my refrence list I colour coded each refrence in the refrence list and then colour coded intext refrencing so that I could clearly identify which sources I have used in what parts.\n",
      "Processing ID: 22 | Text: I used the feedback from assignment 1, by refining my words and getting more to the point about what I wanted to say, I also found it important to define terms throughout to better highlight my understanding \n",
      "Processing ID: 23 | Text: I began assessment one by reading both the provided articles. Once I chose the 'Including videos in early childhood lessons' article, I began my search via the link provided in our assessment outline to find an article with similar context regarding the inclusion of videos or technology in early childhood education. I explored with the use of the advanced search options and read several articles before deciding on, ' Visual art as digital play for young children'. The next step was reading each article, high-lighting and making notes on the key ideas in each article. Deciphering the similarities and differences between each of the papers and began forming my analysis. I used the Marking Rubic to plan and structure the content and layout of my assignment. Initially, I spent a lot of time reading the assessment resources, especially on the correct manner in which to reference throughout a journal article review. I then began writing my reviews on both pieces, continuously referring back to my notes and key ideas. Once I had completed the initial draft of each review, I began reflecting back on what points I had included and what parts I wanted to draw upon in my analysis at the conclusion of the assessment. In doing this, I found that some small sections could be removed and be replaced with slightly more specific content relating to the similarities and differences I was expressing in the analysis. By the completion of my journal article review I realized that I had past the maximum word limit provided for the assessment and began re-reading and removing sentences and points made throughout the task that weren't needed in supporting the review. To finalize the assignment, I printed my paper and read it out loud, highlighting areas I wished to refine or edit before submission. \n",
      "Processing ID: 24 | Text: in assessment 1, my tutor suggested me to look at the apa 7 reference guiding, and I followed the guiding for the reference\n",
      "i also connected my topic with several course readings to make my points more supportive.\n"
     ]
    }
   ],
   "source": [
    "def process_excel_with_openai(excel_file_path, num_api_calls, model):\n",
    "    \"\"\"\n",
    "    Processes an Excel file and makes multiple API calls for each row of data.\n",
    "\n",
    "    Args:\n",
    "        excel_file_path (str): Path to the Excel file.\n",
    "        num_api_calls (int): Number of times to call the API for each row.\n",
    "        model (str): The model to be used for API calls. Some of the options\n",
    "        include gpt-4-0125-preview, gpt-3.5-turbo-0125, or gpt-4-turbo-preview\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the workbook and select the active worksheet\n",
    "    workbook = openpyxl.load_workbook(excel_file_path)\n",
    "    worksheet = workbook.active  # Assuming the data is in the active sheet\n",
    "\n",
    "    # Dictionary to store the responses for each row\n",
    "    reasoning_dict = {}\n",
    "    count_of_reflections = 0\n",
    "\n",
    "    # Iterate over rows starting from the second row (assuming first row is header)\n",
    "    for row in worksheet.iter_rows(min_row=2):\n",
    "        id_cell, text_cell = row[0], row[1]\n",
    "\n",
    "        # Check if the ID cell contains a numeric value\n",
    "        if is_numeric(val=id_cell.value):\n",
    "          count_of_reflections += 1\n",
    "          print(f\"Processing ID: {id_cell.value} | Text: {text_cell.value}\")\n",
    "\n",
    "          # Dictionary to store responses for multiple API calls\n",
    "          bootstrap_dict = {}\n",
    "          for run in range(num_api_calls):\n",
    "            # Prepare the user prompt by appending the text from the cell\n",
    "            user_p = user_prompt + '\\\\n\"' + text_cell.value\n",
    "\n",
    "            # Call the OpenAI API\n",
    "            response = call_openai_api(system_prompt=system_prompt,\n",
    "                                       user_prompt=user_p,\n",
    "                                       model = model)\n",
    "\n",
    "            # Store the response in the bootstrap dictionary\n",
    "            bootstrap_dict[run+1] = response\n",
    "\n",
    "          # Store the bootstrap dictionary in the reasoning dictionary\n",
    "          reasoning_dict[id_cell.value] = bootstrap_dict\n",
    "\n",
    "    # Print the results\n",
    "    print_reasoning_excel(reasoning_dict)\n",
    "    print_coding(reasoning_dict, count_of_reflections, num_api_calls)\n",
    "\n",
    "# Setup the parameters and invoke the function\n",
    "excel_file_path = '/content/sourcedata/10-examples.xlsx'\n",
    "num_api_calls = 3  # Number of times you want to call the API for each valid row\n",
    "model = 'gpt-4o'\n",
    "\n",
    "process_excel_with_openai(excel_file_path,\n",
    "                          num_api_calls,\n",
    "                          model=model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiyS-aKo2Qca"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
