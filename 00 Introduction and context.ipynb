{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adde7785-9f8f-4543-9413-48c243d15001",
   "metadata": {},
   "source": [
    "# LLM crash course\n",
    "\n",
    "Almost every task in NLP falls under two big headings:\n",
    "- Document annotation (classification + regression problems)\n",
    "- Information extraction\n",
    "\n",
    "And almost all _models_ can be described as \"text-to-X\" models, for some choice of X:\n",
    "- Text-to-numbers: all classification and regression models, and many information extraction models.\n",
    "- Text-to-text (aka \"sequence to sequence\"): all text generation models like OpenAssistant, Mistral, ChatGPT, etc.\n",
    "- Text-to-image and text-to-video: models like Stable Diffusion, Midjourney, etc.  We don't be talking about these today.\n",
    "\n",
    "## Document Annotation\n",
    "\n",
    "Document annotation problems are ultimately just classification and regression problems.  The only difference is that the input is text, rather than tabular or numeric data.\n",
    "\n",
    "Given a piece of text, apply some label or set of labels to it.  This is  E.g.:\n",
    "- For a product review, is this user likely to buy from you again?  (Yes/no; binary classification)\n",
    "- For a student essay, what writing skills are they demonstrating?  (Multi-output classification)\n",
    "- For a support ticket, what is the problem the user needs help with?  (Multi-class classification)\n",
    "- From a description of a vehicle, estimate the annual maintenance cost.  (Regression)\n",
    "\n",
    "## Information extraction\n",
    "\n",
    "Information extraction is used to retrieve specific pieces of information from a piece of text.  E.g.:\n",
    "- What general topic is this text about?  (Topic modeling)\n",
    "- What's the general gist of this piece of text?  (Summarization)\n",
    "- What does this text express positive/negative feelings about?  (Aspect-based sentiment analysis)\n",
    "\n",
    "## Text-to-Numbers\n",
    "\n",
    "These models take text in and output numeric results:\n",
    "- A 1 or 0 to identify the presence, or absence, of some feature.\n",
    "- A number between 0 and 1 to indicate a probability.\n",
    "- A vector of numbers to represent anything you can represent in a vector.\n",
    "\n",
    "What the output numbers \"mean\" varies by task.  1/0 outputs might be flagging potential fraud, or toxic language, or the successful use of some writing technique.\n",
    "\n",
    "## Text-to-Text\n",
    "\n",
    "Text goes in, text comes out.  For these models to be useful, the output text should be somehow conditioned on the input text.  E.g.:\n",
    "- Put a long document in, and produce a summary of it.\n",
    "- Put some text in, and guess the next word.  (this is how all generative models currently work--next-word-prediction tasks).\n",
    "    - A little secret: these models are secretly text-to-number models.  The output is a vector of probabilities corresponding to possible next words, and the model samples from this probability to generate new text.\n",
    "- Put some text in, and translate it into another language.\n",
    "\n",
    "## Text-to-Image and Text-to-Video\n",
    "\n",
    "Put some text in, and get a picture or video or something similar out.  We won't be discussing these models today."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
